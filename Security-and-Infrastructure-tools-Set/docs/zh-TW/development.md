# é–‹ç™¼è€…æŒ‡å—

> æœ¬æ–‡ä»¶æä¾›æ“´å±•å’Œè‡ªè¨‚å°ˆæ¡ˆçš„å®Œæ•´æŒ‡å—

## ç›®éŒ„

- [é–‹ç™¼ç’°å¢ƒè¨­å®š](#é–‹ç™¼ç’°å¢ƒè¨­å®š)
- [å°ˆæ¡ˆçµæ§‹](#å°ˆæ¡ˆçµæ§‹)
- [æ·»åŠ æ–°æƒæå·¥å…·](#æ·»åŠ æ–°æƒæå·¥å…·)
- [è‡ªè¨‚ Parser](#è‡ªè¨‚-parser)
- [æ“´å±• API](#æ“´å±•-api)
- [æ¸¬è©¦æŒ‡å—](#æ¸¬è©¦æŒ‡å—)
- [è²¢ç»æµç¨‹](#è²¢ç»æµç¨‹)

---

## é–‹ç™¼ç’°å¢ƒè¨­å®š

### å·¥å…·éœ€æ±‚

```bash
# é–‹ç™¼å·¥å…·
- Docker Desktop 20.10+
- Docker Compose 2.0+
- Git
- ç¨‹å¼ç¢¼ç·¨è¼¯å™¨ï¼ˆVS Code æ¨è–¦ï¼‰
- Make
- curl / httpieï¼ˆAPI æ¸¬è©¦ï¼‰
- jqï¼ˆJSON è™•ç†ï¼‰
```

### VS Code æ¨è–¦æ“´å±•

```json
{
  "recommendations": [
    "ms-azuretools.vscode-docker",
    "ms-python.python",
    "golang.go",
    "hashicorp.terraform",
    "redhat.vscode-yaml",
    "ms-vscode.makefile-tools",
    "esbenp.prettier-vscode"
  ]
}
```

---

## å°ˆæ¡ˆçµæ§‹

```
Security-and-Infrastructure-tools-Set/
â”œâ”€â”€ Docker/
â”‚   â”œâ”€â”€ compose/
â”‚   â”‚   â””â”€â”€ docker-compose.yml       # ä¸»è¦ç·¨æ’æª”æ¡ˆ
â”‚   â”œâ”€â”€ images/                      # è‡ªè¨‚ Dockerfile
â”‚   â”‚   â”œâ”€â”€ scanner-custom/
â”‚   â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ parser-custom/
â”‚   â”‚       â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ configs/                     # æœå‹™é…ç½®æª”
â”‚       â”œâ”€â”€ traefik/
â”‚       â”œâ”€â”€ vault/
â”‚       â””â”€â”€ prometheus/
â”œâ”€â”€ Make_Files/
â”‚   â””â”€â”€ Makefile                     # Make å‘½ä»¤å®šç¾©
â”œâ”€â”€ init_scripts/
â”‚   â”œâ”€â”€ 01-init-sql                  # è³‡æ–™åº«åˆå§‹åŒ–
â”‚   â””â”€â”€ 02-custom-tables.sql         # è‡ªè¨‚è¡¨çµæ§‹
â”œâ”€â”€ scripts/                         # å¯¦ç”¨è…³æœ¬
â”‚   â”œâ”€â”€ parsers/                     # è§£æå™¨è…³æœ¬
â”‚   â”‚   â”œâ”€â”€ nuclei_parser.py
â”‚   â”‚   â””â”€â”€ custom_parser.py
â”‚   â”œâ”€â”€ backup.sh                    # å‚™ä»½è…³æœ¬
â”‚   â””â”€â”€ health-check.sh              # å¥åº·æª¢æŸ¥
â”œâ”€â”€ docs/                            # æ–‡ä»¶
â”‚   â”œâ”€â”€ zh-TW/
â”‚   â””â”€â”€ en/
â”œâ”€â”€ examples/                        # ä½¿ç”¨ç¯„ä¾‹
â”‚   â”œâ”€â”€ scan-examples.sh
â”‚   â””â”€â”€ query-examples.sql
â”œâ”€â”€ tests/                           # æ¸¬è©¦æª”æ¡ˆ
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ .env.template                    # ç’°å¢ƒè®Šæ•¸ç¯„æœ¬
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## æ·»åŠ æ–°æƒæå·¥å…·

### ç¯„ä¾‹ï¼šæ•´åˆ ZAP (OWASP Zed Attack Proxy)

#### æ­¥é©Ÿ 1: ç ”ç©¶å·¥å…·

```bash
# æ¸¬è©¦ Docker æ˜ åƒ
docker run --rm owasp/zap2docker-stable zap-cli --help

# äº†è§£è¼¸å‡ºæ ¼å¼
docker run --rm owasp/zap2docker-stable zap-baseline.py -t https://example.com
```

#### æ­¥é©Ÿ 2: æ·»åŠ åˆ° docker-compose.yml

```yaml
# Docker/compose/docker-compose.yml
services:
  scanner-zap:
    image: owasp/zap2docker-stable:latest
    volumes:
      - scan_results:/zap/wrk
    networks:
      - security_net
    command: ["zap-cli", "--help"]
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
```

#### æ­¥é©Ÿ 3: æ·»åŠ  Makefile å‘½ä»¤

```makefile
# Make_Files/Makefile
scan-zap:
	@echo "Running ZAP scan on $(TARGET)..."
	docker-compose run --rm scanner-zap \
		zap-baseline.py -t $(TARGET) \
		-J /zap/wrk/zap-$(shell date +%Y%m%d-%H%M%S).json \
		-r /zap/wrk/zap-$(shell date +%Y%m%d-%H%M%S).html
	@echo "Scan complete. Results in scan_results/"
```

#### æ­¥é©Ÿ 4: å‰µå»ºè³‡æ–™åº«è¡¨

```sql
-- init_scripts/02-zap-tables.sql
CREATE TABLE IF NOT EXISTS zap_results (
    id SERIAL PRIMARY KEY,
    scan_job_id INTEGER REFERENCES scan_jobs(id) ON DELETE CASCADE,
    alert_name VARCHAR(255) NOT NULL,
    risk VARCHAR(20) NOT NULL,  -- High, Medium, Low, Informational
    confidence VARCHAR(20) NOT NULL,
    url VARCHAR(500) NOT NULL,
    parameter VARCHAR(255),
    attack VARCHAR(255),
    evidence TEXT,
    solution TEXT,
    reference TEXT,
    cwe_id INTEGER,
    wasc_id INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_zap_risk ON zap_results(risk);
CREATE INDEX idx_zap_scan_job ON zap_results(scan_job_id);
```

#### æ­¥é©Ÿ 5: å‰µå»º Parser

```python
#!/usr/bin/env python3
# scripts/parsers/zap_parser.py

import json
import psycopg2
import os
from datetime import datetime

def parse_zap_result(json_file):
    """è§£æ ZAP JSON è¼¸å‡º"""
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    # é€£æ¥è³‡æ–™åº«
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST', 'postgres'),
        database=os.getenv('DB_NAME', 'security'),
        user=os.getenv('DB_USER', 'sectools'),
        password=os.getenv('DB_PASSWORD')
    )
    cursor = conn.cursor()
    
    # å‰µå»ºæƒæä»»å‹™
    cursor.execute("""
        INSERT INTO scan_jobs (scan_type, target, status, started_at, completed_at)
        VALUES (%s, %s, %s, %s, %s)
        RETURNING id
    """, ('zap', data.get('@target'), 'completed', datetime.now(), datetime.now()))
    
    scan_job_id = cursor.fetchone()[0]
    
    # è§£ææ¯å€‹ alert
    for site in data.get('site', []):
        for alert in site.get('alerts', []):
            # æ’å…¥ zap_results
            cursor.execute("""
                INSERT INTO zap_results (
                    scan_job_id, alert_name, risk, confidence,
                    url, parameter, attack, evidence, solution, reference, cwe_id, wasc_id
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                scan_job_id,
                alert.get('name'),
                alert.get('riskdesc', '').split()[0],  # "High (Medium)" -> "High"
                alert.get('confidence'),
                alert.get('url'),
                alert.get('param'),
                alert.get('attack'),
                alert.get('evidence'),
                alert.get('solution'),
                alert.get('reference'),
                alert.get('cweid'),
                alert.get('wascid')
            ))
            
            # åŒæ™‚æ’å…¥é€šç”¨ scan_findings è¡¨
            cursor.execute("""
                INSERT INTO scan_findings (
                    scan_job_id, severity, title, description, host, evidence
                ) VALUES (%s, %s, %s, %s, %s, %s::jsonb)
            """, (
                scan_job_id,
                alert.get('riskdesc', '').split()[0].lower(),
                alert.get('name'),
                alert.get('desc'),
                alert.get('url'),
                json.dumps({'parameter': alert.get('param'), 'attack': alert.get('attack')})
            ))
    
    conn.commit()
    cursor.close()
    conn.close()
    
    print(f"âœ… Parsed ZAP results. Scan Job ID: {scan_job_id}")

if __name__ == '__main__':
    import sys
    if len(sys.argv) != 2:
        print("Usage: zap_parser.py <zap_json_file>")
        sys.exit(1)
    
    parse_zap_result(sys.argv[1])
```

#### æ­¥é©Ÿ 6: å‰µå»º Parser å®¹å™¨

```dockerfile
# Docker/images/parser-zap/Dockerfile
FROM python:3.11-alpine

RUN pip install --no-cache-dir psycopg2-binary

COPY scripts/parsers/zap_parser.py /app/parser.py

WORKDIR /app
CMD ["python", "parser.py"]
```

```yaml
# docker-compose.yml
services:
  parser-zap:
    build: ./Docker/images/parser-zap
    environment:
      DB_HOST: postgres
      DB_PASSWORD: ${DB_PASSWORD}
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - scan_results:/results
    networks:
      - security_net
```

#### æ­¥é©Ÿ 7: æ¸¬è©¦æ•´åˆ

```bash
# 1. é‡å»ºæœå‹™
docker-compose build parser-zap

# 2. å•Ÿå‹•æœå‹™
docker-compose up -d

# 3. åŸ·è¡Œ ZAP æƒæ
make scan-zap TARGET=https://example.com

# 4. æ‰‹å‹•åŸ·è¡Œ Parserï¼ˆå¦‚æœæœªè‡ªå‹•åŒ–ï¼‰
docker-compose run --rm parser-zap \
    python /app/parser.py /results/zap-20251017-103045.json

# 5. æŸ¥è©¢çµæœ
docker exec -it postgres psql -U sectools -d security \
    -c "SELECT * FROM zap_results ORDER BY id DESC LIMIT 5;"
```

---

## è‡ªè¨‚ Parser

### Parser é–‹ç™¼æ¨¡æ¿

```python
#!/usr/bin/env python3
# scripts/parsers/template_parser.py

import json
import psycopg2
import os
from datetime import datetime
from typing import Dict, List, Any

class ScanParser:
    """é€šç”¨æƒæçµæœè§£æå™¨åŸºé¡"""
    
    def __init__(self):
        self.conn = self.connect_db()
        self.cursor = self.conn.cursor()
    
    def connect_db(self):
        """é€£æ¥ PostgreSQL"""
        return psycopg2.connect(
            host=os.getenv('DB_HOST', 'postgres'),
            database=os.getenv('DB_NAME', 'security'),
            user=os.getenv('DB_USER', 'sectools'),
            password=os.getenv('DB_PASSWORD')
        )
    
    def create_scan_job(self, scan_type: str, target: str) -> int:
        """å‰µå»ºæƒæä»»å‹™è¨˜éŒ„"""
        self.cursor.execute("""
            INSERT INTO scan_jobs (scan_type, target, status, started_at, completed_at)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING id
        """, (scan_type, target, 'completed', datetime.now(), datetime.now()))
        
        return self.cursor.fetchone()[0]
    
    def insert_finding(self, scan_job_id: int, finding: Dict[str, Any]):
        """æ’å…¥ç™¼ç¾é …"""
        self.cursor.execute("""
            INSERT INTO scan_findings (
                scan_job_id, severity, title, description, host, port, evidence
            ) VALUES (%s, %s, %s, %s, %s, %s, %s::jsonb)
        """, (
            scan_job_id,
            finding.get('severity'),
            finding.get('title'),
            finding.get('description'),
            finding.get('host'),
            finding.get('port'),
            json.dumps(finding.get('evidence', {}))
        ))
    
    def parse(self, file_path: str):
        """è§£ææª”æ¡ˆï¼ˆéœ€å­é¡å¯¦ä½œï¼‰"""
        raise NotImplementedError("Subclass must implement parse()")
    
    def commit(self):
        """æäº¤è³‡æ–™åº«è®Šæ›´"""
        self.conn.commit()
    
    def close(self):
        """é—œé–‰é€£æ¥"""
        self.cursor.close()
        self.conn.close()

class MyCustomParser(ScanParser):
    """è‡ªè¨‚æƒæå™¨è§£æå™¨"""
    
    def parse(self, file_path: str):
        """è§£æè‡ªè¨‚æ ¼å¼"""
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        # å‰µå»ºæƒæä»»å‹™
        scan_job_id = self.create_scan_job('my_scanner', data.get('target'))
        
        # è§£æç™¼ç¾é …
        for item in data.get('findings', []):
            finding = {
                'severity': self._map_severity(item['level']),
                'title': item['name'],
                'description': item['details'],
                'host': item['url'],
                'port': item.get('port'),
                'evidence': {'raw': item}
            }
            self.insert_finding(scan_job_id, finding)
        
        self.commit()
        print(f"âœ… Parsed {len(data.get('findings', []))} findings. Job ID: {scan_job_id}")
    
    def _map_severity(self, level: str) -> str:
        """æ˜ å°„åš´é‡åº¦"""
        mapping = {
            '1': 'low',
            '2': 'medium',
            '3': 'high',
            '4': 'critical'
        }
        return mapping.get(str(level), 'info')

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) != 2:
        print("Usage: template_parser.py <scan_result_file>")
        sys.exit(1)
    
    parser = MyCustomParser()
    try:
        parser.parse(sys.argv[1])
    finally:
        parser.close()
```

---

## æ“´å±• API

### FastAPI ç¯„ä¾‹

```python
# scripts/api/main.py
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Optional
import psycopg2
import os

app = FastAPI(title="Security Stack API", version="1.0.0")

# è³‡æ–™åº«é€£æ¥
def get_db():
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST', 'postgres'),
        database=os.getenv('DB_NAME', 'security'),
        user=os.getenv('DB_USER', 'sectools'),
        password=os.getenv('DB_PASSWORD')
    )
    try:
        yield conn
    finally:
        conn.close()

# Pydantic Models
class ScanJob(BaseModel):
    id: int
    scan_type: str
    target: str
    status: str
    started_at: str

class Finding(BaseModel):
    id: int
    severity: str
    title: str
    description: Optional[str]
    host: Optional[str]
    discovered_at: str

# API Endpoints
@app.get("/")
def read_root():
    return {"message": "Security Stack API v1.0", "status": "running"}

@app.get("/api/v1/scans", response_model=List[ScanJob])
def get_scans(
    limit: int = 10,
    scan_type: Optional[str] = None,
    db=Depends(get_db)
):
    """ç²å–æƒæä»»å‹™åˆ—è¡¨"""
    cursor = db.cursor()
    
    if scan_type:
        cursor.execute("""
            SELECT id, scan_type, target, status, started_at::text
            FROM scan_jobs
            WHERE scan_type = %s
            ORDER BY started_at DESC
            LIMIT %s
        """, (scan_type, limit))
    else:
        cursor.execute("""
            SELECT id, scan_type, target, status, started_at::text
            FROM scan_jobs
            ORDER BY started_at DESC
            LIMIT %s
        """, (limit,))
    
    results = cursor.fetchall()
    cursor.close()
    
    return [
        {"id": r[0], "scan_type": r[1], "target": r[2], "status": r[3], "started_at": r[4]}
        for r in results
    ]

@app.get("/api/v1/scans/{scan_id}/findings", response_model=List[Finding])
def get_findings(scan_id: int, db=Depends(get_db)):
    """ç²å–ç‰¹å®šæƒæçš„ç™¼ç¾é …"""
    cursor = db.cursor()
    
    cursor.execute("""
        SELECT id, severity, title, description, host, discovered_at::text
        FROM scan_findings
        WHERE scan_job_id = %s
        ORDER BY discovered_at DESC
    """, (scan_id,))
    
    results = cursor.fetchall()
    cursor.close()
    
    if not results:
        raise HTTPException(status_code=404, detail="Scan not found or no findings")
    
    return [
        {
            "id": r[0],
            "severity": r[1],
            "title": r[2],
            "description": r[3],
            "host": r[4],
            "discovered_at": r[5]
        }
        for r in results
    ]

@app.get("/api/v1/stats")
def get_stats(db=Depends(get_db)):
    """ç²å–çµ±è¨ˆè³‡æ–™"""
    cursor = db.cursor()
    
    cursor.execute("SELECT * FROM scan_summary")
    results = cursor.fetchall()
    cursor.close()
    
    return {
        "summary": [
            {"scan_type": r[0], "total": r[1], "completed": r[2], "failed": r[3]}
            for r in results
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### éƒ¨ç½² API

```dockerfile
# Docker/images/api-server/Dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN pip install --no-cache-dir fastapi uvicorn psycopg2-binary

COPY scripts/api/main.py /app/

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
services:
  api-server:
    build: ./Docker/images/api-server
    ports:
      - "8000:8000"
    environment:
      DB_HOST: postgres
      DB_PASSWORD: ${DB_PASSWORD}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - security_net
```

---

## æ¸¬è©¦æŒ‡å—

### å–®å…ƒæ¸¬è©¦

```python
# tests/unit/test_parser.py
import unittest
from scripts.parsers.nuclei_parser import NucleiParser

class TestNucleiParser(unittest.TestCase):
    
    def test_severity_mapping(self):
        parser = NucleiParser()
        self.assertEqual(parser._map_severity('critical'), 'critical')
        self.assertEqual(parser._map_severity('high'), 'high')
    
    def test_parse_valid_json(self):
        parser = NucleiParser()
        result = parser.parse('tests/fixtures/nuclei-sample.json')
        self.assertIsNotNone(result)

if __name__ == '__main__':
    unittest.main()
```

### æ•´åˆæ¸¬è©¦

```bash
#!/bin/bash
# tests/integration/test_full_scan.sh

set -e

echo "ğŸ§ª Running integration tests..."

# 1. å•Ÿå‹•æœå‹™
cd Make_Files
make up
sleep 30

# 2. åŸ·è¡Œæ¸¬è©¦æƒæ
make scan-nuclei TARGET=https://scanme.nmap.org

# 3. é©—è­‰è³‡æ–™åº«è¨˜éŒ„
COUNT=$(docker exec postgres psql -U sectools -d security -t -c \
    "SELECT COUNT(*) FROM scan_jobs WHERE target='https://scanme.nmap.org'")

if [ "$COUNT" -gt 0 ]; then
    echo "âœ… Integration test passed!"
else
    echo "âŒ Integration test failed!"
    exit 1
fi

# 4. æ¸…ç†
make down
```

---

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0  
**æœ€å¾Œæ›´æ–°**: 2025-10-17

