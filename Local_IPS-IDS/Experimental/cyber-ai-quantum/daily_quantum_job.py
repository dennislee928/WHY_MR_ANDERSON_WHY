#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥è‡ªå‹•åŒ–é‡å­ä½œæ¥­
æ•´åˆäº† QASM ç”Ÿæˆã€æäº¤ã€ç›£æ§å’Œçµæœç²å–ã€‚

åŸ·è¡Œæµç¨‹:
1. è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹åƒæ•¸ (å¦‚æœå­˜åœ¨)
2. ç”Ÿæˆå‹•æ…‹ QASM é›»è·¯ (åŸºæ–¼ç‰¹å¾µå’Œæ¬Šé‡)
3. é€£æ¥ IBM Quantum
4. è½‰è­¯ä¸¦æäº¤ä½œæ¥­
5. ç­‰å¾…ä½œæ¥­å®Œæˆ
6. ç²å–ä¸¦å„²å­˜çµæœ
7. è‡ªå‹•åˆ†æçµæœä¸¦ç”Ÿæˆå ±å‘Š
"""

import os
import sys
import time
import json
from datetime import datetime
from dotenv import load_dotenv
import numpy as np

# Windows UTF-8 å…¼å®¹æ€§
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler
from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager

# å°å…¥æˆ‘å€‘å»ºç«‹çš„å‹•æ…‹ QASM ç”Ÿæˆå™¨
from generate_dynamic_qasm import create_zero_day_classifier_circuit
from analyze_results import analyze_classification_results, save_analysis_report

# --- è¼‰å…¥ç’°å¢ƒ ---
load_dotenv()
token = os.getenv('IBM_QUANTUM_TOKEN')
if not token:
    print("[ERROR] IBM_QUANTUM_TOKEN not found.")
    print("[INFO] è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š IBM_QUANTUM_TOKEN")
    sys.exit(1)

# --- è¨­å®š ---
QUBITS = 7
SHOTS = 2048  # å»ºè­°ä½¿ç”¨æ›´é«˜çš„ shots ä»¥ç²å¾—æ›´ç©©å®šçš„çµ±è¨ˆçµæœ
USE_SIMULATOR = os.getenv('USE_SIMULATOR', 'false').lower() == 'true'
MODEL_FILE = "quantum_classifier_model.json"
RESULTS_DIR = "results"
CLASSIFICATION_THRESHOLD = 0.5


def load_trained_model():
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹åƒæ•¸"""
    try:
        with open(MODEL_FILE, 'r', encoding='utf-8') as f:
            model_info = json.load(f)
        trained_weights = np.array(model_info['trained_weights'])
        print(f"[OK] æˆåŠŸè¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹åƒæ•¸ (ä¾†è‡ª {MODEL_FILE})")
        print(f"     æ¨¡å‹è¨“ç·´æ™‚é–“: {model_info.get('timestamp', 'N/A')}")
        print(f"     è¨“ç·´æº–ç¢ºç‡: {model_info.get('accuracy', 'N/A')}")
        return trained_weights, model_info
    except FileNotFoundError:
        print(f"[WARNING] æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ '{MODEL_FILE}'")
        print("[INFO] å°‡ä½¿ç”¨é è¨­è§’åº¦é€²è¡Œé æ¸¬")
        print("[HINT] åŸ·è¡Œ train_quantum_classifier.py ä¾†è¨“ç·´æ¨¡å‹")
        return None, None
    except Exception as e:
        print(f"[ERROR] è¼‰å…¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None


def get_features_from_logs():
    """
    å¾ Windows Agent Logs ç²å–ç‰¹å¾µå‘é‡
    
    TODO: å¯¦ä½œçœŸå¯¦çš„ç‰¹å¾µæå–é‚è¼¯
    ç›®å‰ä½¿ç”¨æ¨¡æ“¬ç‰¹å¾µ
    """
    # !!! é‡è¦ !!!
    # åœ¨çœŸå¯¦æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æ‡‰è©²:
    # 1. å¾è³‡æ–™åº«æˆ–æª”æ¡ˆç³»çµ±è®€å–æœ€æ–°çš„ Windows Log
    # 2. å‘¼å« feature_extractor.py é€²è¡Œç‰¹å¾µæå–
    # 3. è¿”å›æ¨™æº–åŒ–çš„ç‰¹å¾µå‘é‡
    
    print("[INFO] æ­£åœ¨ç²å–æ—¥èªŒç‰¹å¾µ...")
    print("[WARNING] ç›®å‰ä½¿ç”¨æ¨¡æ“¬ç‰¹å¾µ (TODO: æ•´åˆçœŸå¯¦ Windows Agent Logs)")
    
    # æ¨¡æ“¬ç‰¹å¾µ
    features = np.random.rand(QUBITS - 1)
    print(f"[INFO] æ¨¡æ“¬ç‰¹å¾µå‘é‡: {np.round(features, 3)}")
    
    return features


def run_daily_job():
    """åŸ·è¡Œæ¯æ—¥é‡å­ä½œæ¥­"""
    print("="*70)
    print("  ğŸš€ é–‹å§‹æ¯æ—¥é›¶æ—¥æ”»æ“Šåµæ¸¬é‡å­ä½œæ¥­")
    print("="*70)
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é‡å­ä½å…ƒæ•¸: {QUBITS}")
    print(f"æ¸¬é‡æ¬¡æ•¸ (Shots): {SHOTS}")
    
    # ç¢ºä¿çµæœç›®éŒ„å­˜åœ¨
    if not os.path.exists(RESULTS_DIR):
        os.makedirs(RESULTS_DIR)
        print(f"[INFO] å‰µå»ºçµæœç›®éŒ„: {RESULTS_DIR}")
    
    # --- 1. è¼‰å…¥æ¨¡å‹ä¸¦ç²å–ç‰¹å¾µ ---
    print(f"\n[1/7] è¼‰å…¥æ¨¡å‹å’Œç²å–ç‰¹å¾µ...")
    trained_weights, model_info = load_trained_model()
    features = get_features_from_logs()
    
    # --- 2. ç”Ÿæˆå‹•æ…‹ QASM é›»è·¯ ---
    print(f"\n[2/7] ç”Ÿæˆ {QUBITS}-qubit åˆ†é¡é›»è·¯...")
    try:
        circuit = create_zero_day_classifier_circuit(features, QUBITS, trained_weights)
        print(f"[OK] é›»è·¯ç”Ÿæˆå®Œç•¢")
        print(f"     é–˜é–€æ•¸: {len(circuit.data)}")
        print(f"     é›»è·¯æ·±åº¦: {circuit.depth()}")
    except Exception as e:
        print(f"[ERROR] é›»è·¯ç”Ÿæˆå¤±æ•—: {e}")
        return None
    
    # --- 3. é€£æ¥ IBM Quantum ---
    print("\n[3/7] é€£æ¥ IBM Quantum...")
    try:
        service = QiskitRuntimeService(channel='ibm_cloud', token=token)
        
        if USE_SIMULATOR:
            print("[INFO] ä½¿ç”¨æ¨¡æ“¬å™¨é€²è¡Œæ¸¬è©¦...")
            backend = service.backend('ibmq_qasm_simulator')
        else:
            print("[INFO] æ­£åœ¨é¸æ“‡å¯ç”¨çš„çœŸå¯¦é‡å­å¾Œç«¯...")
            backend = service.least_busy(operational=True, simulator=False)
        
        print(f"[OK] é€£æ¥æˆåŠŸï¼é¸æ“‡å¾Œç«¯: {backend.name}")
        print(f"     å¾Œç«¯ç‹€æ…‹: {backend.status().status_msg}")
    except Exception as e:
        print(f"[ERROR] é€£æ¥å¤±æ•—: {e}")
        print("[INFO] è«‹æª¢æŸ¥ç¶²è·¯é€£ç·šå’Œ IBM Quantum Token")
        return None

    # --- 4. è½‰è­¯ä¸¦æäº¤ä½œæ¥­ ---
    print("\n[4/7] è½‰è­¯ä¸¦æäº¤ä½œæ¥­...")
    try:
        pm = generate_preset_pass_manager(backend=backend, optimization_level=1)
        transpiled_qc = pm.run(circuit)
        
        print(f"[OK] é›»è·¯è½‰è­¯å®Œæˆ")
        print(f"     åŸå§‹é–˜é–€æ•¸: {len(circuit.data)}")
        print(f"     è½‰è­¯å¾Œé–˜é–€æ•¸: {len(transpiled_qc.data)}")
        
        sampler = Sampler(backend)
        job = sampler.run([transpiled_qc], shots=SHOTS)
        job_id = job.job_id()
        print(f"[SUCCESS] ä½œæ¥­å·²æäº¤ï¼ Job ID: {job_id}")
        
        # å„²å­˜ä½œæ¥­è³‡è¨Š
        job_info_file = f"{RESULTS_DIR}/job_{job_id}_info.txt"
        with open(job_info_file, 'w', encoding='utf-8') as f:
            f.write(f"Job ID: {job_id}\n")
            f.write(f"Backend: {backend.name}\n")
            f.write(f"Submitted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Shots: {SHOTS}\n")
            f.write(f"Qubits: {QUBITS}\n")
            f.write(f"Features: {features.tolist()}\n")
            if trained_weights is not None:
                f.write(f"Weights: {trained_weights.tolist()}\n")
        print(f"[INFO] ä½œæ¥­è³‡è¨Šå·²å„²å­˜è‡³: {job_info_file}")
        
    except Exception as e:
        print(f"[ERROR] æäº¤å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

    # --- 5. ç­‰å¾…ä½œæ¥­å®Œæˆ ---
    print("\n[5/7] ç­‰å¾…ä½œæ¥­çµæœ...")
    print("[INFO] é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜åˆ°å¹¾å°æ™‚ï¼Œå–æ±ºæ–¼ä½‡åˆ—ç‹€æ³")
    
    max_wait_time = 3600  # æœ€å¤šç­‰å¾… 1 å°æ™‚
    check_interval = 30  # æ¯ 30 ç§’æª¢æŸ¥ä¸€æ¬¡
    elapsed_time = 0
    
    try:
        while elapsed_time < max_wait_time:
            status = job.status()
            print(f"  [{datetime.now().strftime('%H:%M:%S')}] ç‹€æ…‹: {status} (å·²ç­‰å¾… {elapsed_time}s)")
            
            if status == 'DONE':
                print("\n[SUCCESS] ä½œæ¥­å®Œæˆï¼")
                break
            elif status in ['ERROR', 'CANCELLED']:
                print(f"\n[ERROR] ä½œæ¥­å¤±æ•—: {status}")
                return None
            
            time.sleep(check_interval)
            elapsed_time += check_interval
        else:
            print(f"\n[WARNING] ç­‰å¾…è¶…æ™‚ ({max_wait_time}s)")
            print(f"[INFO] ä½œæ¥­ä»åœ¨åŸ·è¡Œä¸­ï¼ŒJob ID: {job_id}")
            print(f"[INFO] ç¨å¾Œå¯ä½¿ç”¨ check_job_status.py æª¢æŸ¥çµæœ")
            return {'job_id': job_id, 'status': 'PENDING'}
        
        result = job.result()
        
    except Exception as e:
        print(f"[ERROR] ç­‰å¾…çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

    # --- 6. ç²å–ä¸¦å„²å­˜çµæœ ---
    print("\n[6/7] è™•ç†ä¸¦å„²å­˜çµæœ...")
    try:
        pub_result = result[0]
        
        # ä½¿ç”¨ä¿®å¾©å¾Œçš„çµæœç²å–æ–¹å¼
        counts = {}
        for key in pub_result.data:
            if hasattr(pub_result.data[key], 'get_counts'):
                counts = pub_result.data[key].get_counts()
                break
        
        if not counts:
            raise RuntimeError("åœ¨çµæœä¸­æ‰¾ä¸åˆ°è¨ˆæ•¸æ•¸æ“šã€‚")

        # å°‡çµæœå„²å­˜ç‚º JSON æª”æ¡ˆ
        result_filename = f"{RESULTS_DIR}/result_{job_id}.json"
        result_data = {
            'job_id': job_id,
            'backend': backend.name,
            'shots': SHOTS,
            'qubits': QUBITS,
            'timestamp': datetime.now().isoformat(),
            'features': features.tolist(),
            'counts': {k: int(v) for k, v in counts.items()}  # ç¢ºä¿ value æ˜¯æ¨™æº– int
        }
        
        if trained_weights is not None:
            result_data['weights'] = trained_weights.tolist()
            result_data['model_info'] = model_info
        
        with open(result_filename, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)

        print(f"[SUCCESS] çµæœå·²å„²å­˜è‡³: {result_filename}")
        print("\næ¸¬é‡çµæœé è¦½:")
        for bitstring, count in sorted(counts.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  {bitstring}: {count} æ¬¡ ({count/SHOTS*100:.1f}%)")
        
    except Exception as e:
        print(f"[ERROR] è™•ç†çµæœå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

    # --- 7. è‡ªå‹•åˆ†æçµæœ ---
    print("\n[7/7] åˆ†æçµæœä¸¦ç”Ÿæˆå ±å‘Š...")
    try:
        analysis_result = analyze_classification_results(
            result_filename, 
            threshold=CLASSIFICATION_THRESHOLD,
            output_report=True
        )
        
        # å„²å­˜åˆ†æå ±å‘Š
        report_filename = f"{RESULTS_DIR}/analysis_{job_id}.json"
        save_analysis_report(analysis_result, report_filename)
        
        print("\n" + "="*70)
        print("  ğŸ‰ æ¯æ—¥ä½œæ¥­å…¨éƒ¨å®Œæˆï¼")
        print("="*70)
        
        return {
            'job_id': job_id,
            'status': 'SUCCESS',
            'result_file': result_filename,
            'analysis_file': report_filename,
            'is_zero_day': analysis_result.get('is_zero_day', False),
            'confidence': analysis_result.get('confidence', 0)
        }
        
    except Exception as e:
        print(f"[ERROR] åˆ†æçµæœå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return {
            'job_id': job_id,
            'status': 'COMPLETED_WITHOUT_ANALYSIS',
            'result_file': result_filename
        }


if __name__ == "__main__":
    try:
        result = run_daily_job()
        if result:
            print(f"\n[FINAL STATUS] {result['status']}")
            if result.get('is_zero_day'):
                print("âš ï¸  è­¦å‘Š: åµæ¸¬åˆ°ç–‘ä¼¼é›¶æ—¥æ”»æ“Šï¼è«‹ç«‹å³æª¢æŸ¥ã€‚")
        else:
            print("\n[FINAL STATUS] FAILED")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\n[INFO] ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\n[CRITICAL ERROR] æœªé æœŸçš„éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

